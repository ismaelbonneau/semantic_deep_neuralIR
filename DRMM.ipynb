{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRMM (Deep Relevance Matching Model)\n",
    "\n",
    "_Ismaël Bonneau_\n",
    "\n",
    "Mots-clés: _Relevance Matching_, _Semantic Matching_, _Neural Models_,\n",
    "_Ad-hoc Retrieval_, _Ranking Models_\n",
    "\n",
    "\n",
    "#### But de ce notebook: Comprendre et construire une architecture **DRMM** fonctionnelle avec **pytorch**, et l'expliquer de façon concise.\n",
    "\n",
    "Un gros bisou à Daniel Godoy pour son tutoriel <a href=\"https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\">comprendre pytorch par l'exemple pas à pas</a> (en Anglais).\n",
    "\n",
    "Pour cela, 2 étapes:\n",
    "\n",
    "- construire la chaîne de pré traitements:\n",
    "    - générer des paires document-requête non pertinentes et pertinentes pour l'apprentissage\n",
    "    - générer des histogrammes d'interaction locales au niveau document-requête\n",
    "- construire l'architecture DRMM\n",
    "\n",
    "Les interractions sont pour le moment des interactions locales sur des word embeddings et sont mesurées comme une similarité cosinus entre les vecteurs des mots de la requête et ceux du document.\n",
    "\n",
    "## En quoi consiste le modèle DRMM?\n",
    "\n",
    "lien vers <a href=\"https://arxiv.org/pdf/1711.08611.pdf\">l'article</a> (en Anglais) par _Jiafeng Guo_, _Yixing Fan_, _Qingyao Ai_, _W. Bruce Croft_ (2017) [1]\n",
    "\n",
    "DRMM (Deep Relevance Matching Model) est un modèle de réseau de neurones profond pour la RI (recherche d'information).\n",
    "\n",
    "Un des objectifs principaux de la RI est de déterminer la **pertinence** d'un document (cela peut être un document court sous forme d'un paragraphe, ou long, voire très long) par rapport à une requête donnée. Un moteur de RI traditionnel retournera alors une liste ordonnée des documents par pertinence par rapport à une requête posée par l'utilisateur, avec en tête de liste les documents les plus pertinents.\n",
    "\n",
    "Un problème qui se pose avec de nombreux modèles de RI est . Certains termes de la requête ne se trouvent pas toujours dans des documents qui sont pourtant pertinents pour cette requête. Pensons à une requête sur la pigeons dans la ville de Paris: Un document qui aurait pour sujet le \"problème envahissant des oiseaux dans la capitale Française\", sans contenir une seule fois les mots Pigeons et Paris, aurait peu de chance d'être considéré comme pertinent.\n",
    "\n",
    "Plusieurs solutions sont donc proposées pour résoudre ce problème.\n",
    "\n",
    "DRMM est un modèle **orienté interactions**, qui applique une fonction apprise (un réseau de neurones n'est rien d'autres qu'une fonction très complexe) à des interactions entre un document et une requête, qui ne font donc pas partie du réseau et ne sont pas apprises. Cette fonction a pour but de calculer un **score pour la paire document-requête**, score d'autant **plus élevé que le document est pertinent pour la requête**.\n",
    "\n",
    "Il se compose de deux parties: \n",
    "\n",
    "- Une partie **\"feed forward matching network\"** qui est un simple perceptron multicouche. Il s'agit dans l'implémentation de [1] d'un perceptron à 3 couches, de taille 30 neurones, 5 neurones, et 1 neurone. Cette partie vient calculer un score pour l'interaction de chaque terme de la requête avec l'ensemble des termes du document. Pour une requête de 5 termes, le partie feed forward matching produira donc un vecteur de dimension 5, pour 1 score par terme de la requête. On a donc un bloc qui prend en entrée une matrice d'interactions des termes de la requête, et qui rend en sortie un vecteur de score pour chaque terme de la requête.\n",
    "\n",
    "- Une partie **\"term gating network\"** qui est un perceptron à une couche. Il s'agit uniquement d'apprendre un vecteur qui vient mutiplier chaque \"vecteur de terme\" de la requête et ensuite pondérer les scores calculés par la partie feed forward. \n",
    "\n",
    "<img src=\"images/DRMMschema.png\" width=\"700\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "On utilise pour cet exemple le dataset <a href=\"https://trec.nist.gov/data/robust/04.guidelines.html\">robust 2004</a>. Il s'agit d'une collection de documents datés de 2004 provenant de journaux américains, le LA times, le Financial times, le Federal Register 94, et le Foreign Broadcast Information Service.\n",
    "\n",
    "\n",
    "| nombre de requêtes      |  jugements de pertinence    |\n",
    "| -------------:|  ------------- |\n",
    "|     **250**       |   **311,410**\n",
    "\n",
    "| collection      |     nombre de documents    |     taille en Mo    |\n",
    "| ------------- |: -------------: |: -------------: |\n",
    "| Financial times      |        210 158        |        564        |\n",
    "| La times       |        131,896        |        475        |\n",
    "| FBIS      |        130,471        |        470        |\n",
    "| FR94      |        55,630        |        395        |\n",
    "| **TOTAL**      |        **528,155**        |        **1904**        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import sep\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "embeddings_path = \"embeddings\"\n",
    "dataset_path = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré traitements: \n",
    "\n",
    "### Obtenir des word embeddings \n",
    "\n",
    "Ce word embedding a les caractéristiques suivantes:\n",
    "\n",
    "- Gensim word2vec Continuous Skipgram\n",
    "- taille de vecteur ${300}$\n",
    "- window ${10}$\n",
    "- entrainé sur la collection robust 2004\n",
    "- lemmatisation avec Krovetz, mots en minuscule\n",
    "- ${116832}$ mots\n",
    "\n",
    "voir script <a href=\"https://github.com/ismaelbonneau/semantic_deep_neuralIR/blob/master/scripts/generate_embeddings.py\">generate_embeddings.py</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "word_vectors = gensim.models.Word2Vec.load('embeddings/model_1')\n",
    "word_vectors.init_sims(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('albi', 0.6107227802276611),\n",
       " ('montpellier', 0.5868463516235352),\n",
       " ('grenoble', 0.537689745426178),\n",
       " ('marseille', 0.5351033210754395),\n",
       " ('tarbe', 0.5294458866119385)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.wv.most_similar(\"toulouse\")[:5] # c'est nooooooormal la mif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On récupère les requêtes:\n",
    "\n",
    "Elles se trouvent sous forme de tuple ([mots clés], [texte de la requête]). On ne garde que les mots clés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new hydroelectric project\n",
      "ireland peace talks\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_punctuation\n",
    "from krovetzstemmer import Stemmer #stemmer pas mal pour la PR\n",
    "ks = Stemmer()\n",
    "\n",
    "def clean(txt):\n",
    "    return \" \".join([ks.stem(t) for t in txt.replace(\",\", \"\").replace(\".\", \"\").split(\" \")])   \n",
    "with open(dataset_path + sep + \"robust2004.txt\", \"r\") as f:\n",
    "    queries = ast.literal_eval(f.read())\n",
    "queries = {d:clean(queries[d][0]) for d in queries}\n",
    "\n",
    "print(queries[\"307\"])\n",
    "print(queries[\"404\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le DRMM a deux entrées: une entrée interactions et une entrée termes.\n",
    "\n",
    "L'entrée termes prend un vecteur d'idf des termes de la requête. Cette information est sensée aider à pondérer les termes de la requête en fonction de leur importance. Un IDF élevé indique un mot \"rare\" dans le corpus, donc probablement important pour la requête. Il faut donc pouvoir récupérer efficacement des **idf**. Pour cela, on construit un dictionnaire terme -> idf qui nous servira dans l'étape d'après.\n",
    "\n",
    "voir script <a href=\"https://github.com/ismaelbonneau/semantic_deep_neuralIR/blob/master/scripts/get_idf.py\">get_idf.py</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idf Paris:  4.317922943975862\n",
      "idf Toulouse:  8.631967635734412\n"
     ]
    }
   ],
   "source": [
    "#bon là on charge du coup vu que le fichier est sauvegardé sur le disque\n",
    "idf = pickle.load(open(\"idf_robust2004.pkl\", \"rb\"))\n",
    "print(\"idf Paris: \", idf[\"paris\"])\n",
    "print(\"idf Toulouse: \", idf[\"toulouse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On prépare dans des fichiers les matrices d'interactions et les vecteurs d'idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query chargé\n",
      "relevance chargé\n",
      "docs chargés\n"
     ]
    }
   ],
   "source": [
    "from datasets import Robust04 #permet de gérer le chargement et le traitement de robust2004\n",
    "\n",
    "inputgenerator = Robust04(intervals=30, model_wv=word_vectors)\n",
    "inputgenerator.load_idf(idf_file=\"idf_robust2004.pkl\")\n",
    "inputgenerator.load_all_query(file_query=\"data/robust2004.txt\")\n",
    "inputgenerator.load_relevance(file_rel=\"data/qrels.robust2004.txt\")\n",
    "inputgenerator.load_all_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cette méthode calcule les matrices d'interraction et les charge dans des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputgenerator.prepare_data_forNN(\"saved_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cette méthode pré calcule les matrices d'interraction des résultats de BM25 et les charge dans des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de requetes: 249.\n",
      "data completed\n"
     ]
    }
   ],
   "source": [
    "inputgenerator.prepare_data_reranking(pickle.load(open(\"results_bm25_robust.pkl\", \"rb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regardons à quoi ressemblent les histogrammes d'interraction:\n",
    "\n",
    "<img src=\"images/avgrelhist307.png\">\n",
    "<img src=\"images/avgnonrelhist307.png\">\n",
    "<img src=\"images/avgrelhist404.png\">\n",
    "<img src=\"images/avgnonrelhist404.png\">\n",
    "\n",
    "On peut voir que les documents jugés \"relevant\" montrent de plus grandes interractions sur l'ensemble des termes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture du modèle\n",
    "\n",
    "### Avec pytorch\n",
    "\n",
    "L'implémentation du modèle est très simple: il s'agit d'un MLP à 2 couches et d'un vecteur pour le termgating (une matrice si on choisit de considérer les embeddings des termes au lieu de l'idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hérite de la classe Pytorch Module\n",
    "class DRMM(torch.nn.Module):\n",
    "    def __init__(self, hist_size, query_term_maxlen, hidden_sizes=[5,1], use_cuda=True):\n",
    "        super(DRMM, self).__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(hist_size, hidden_sizes[0]), nn.Tanh(), \n",
    "            nn.Linear(hidden_sizes[0], hidden_sizes[1]), nn.Tanh())\n",
    "        # term gating (scalar)\n",
    "        self.termgating = torch.nn.Parameter(torch.rand(1), requires_grad=True)\n",
    "    \n",
    "    def forward(self, interractions, termvector):\n",
    "        \"\"\"\n",
    "        interractions: (query_term_maxlen, hist_size)\n",
    "        termvector: (1, query_term_maxlen)\n",
    "        \"\"\"\n",
    "        #partie histogramme\n",
    "        interractions_output = self.mlp(interractions).squeeze()\n",
    "        # partie term gating\n",
    "        gating_output = torch.nn.functional.softmax((self.termgating * termvector).squeeze(), dim=1)\n",
    "        #combiner les 2 avec un produit scalaire\n",
    "        axis = 1\n",
    "        s = torch.sum(gating_output * interractions_output, dim = axis)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de coût à optimiser: **Margin Ranking Hinge Loss**\n",
    "\n",
    "Objectif: Pour une requête, étant donné deux documents ${d^+}$ et ${d^-}$ tels que ${d^+}$ doit être ordonné avant ${d^-}$ dans les résultats de pertinence, cette loss cherche à attribuer un score plus élevé à ${d^+}$ qu'à ${d^-}$, de sorte qu'il soit au moins égal à une certaine marge (1, dans notre cas).\n",
    "\n",
    "Cette fonction peut aussi être vue comme une fonction qui cherche à minimiser le nombre de paires mal ordonnées dans la liste finale!\n",
    "\n",
    "${rankingHingeLoss(d^+, d^-) = max(0,1 - s(d^+) + s(d^-))}$ où ${s(d^+)}$ est le score de ${d^+}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MarginRankingLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On va créer une classe de Dataset qui contient les paires pertinentes et les paires non pertinentes.\n",
    "\n",
    "Plus précisément, la classe Dataset de Pytorch est un wrapper pour X (traditionnellement les vecteurs de features) et Y (traditionnellement les labels). Ici, on a pas besoin de vecteur de labels. On peut donc transformer l'utilisation de la classe pour mettre dans X une matrice de paires (interractions relevant, vecteur de termes relevant) et dans Y la même matrice, pour les paires non pertinentes. L'avantage est que lors du shuffle avec le DataLoader, on conservera l'alignement doc pertinent/non pertinent pour une requête et on ne sera pas embêté pour utiliser la ranking hinge loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DrmmDataset(Dataset):\n",
    "    def __init__(self, pos_tensor, neg_tensor):\n",
    "        self.x = pos_tensor\n",
    "        self.y = neg_tensor\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut maintenant tester le modèle avec des métriques de RI:\n",
    "\n",
    "Pour chacune des requêtes de test, on récupère les 2000 premiers documents retournés par *BM25*. Nous procédons en réordonnant cette liste de documents avec notre modèle *DRMM* appris, et nous calculons des performances sur les 1000 premiers documents de ce re ranking sur un ensemble de métriques de RI (**NDCG@20**, **MAP**, **P@20**), en le comparant avec le ranking original *BM25*.\n",
    "\n",
    "Pour BM25, l'indexation a été faite comme suit:\n",
    "\n",
    "- indexation sur le texte du document et non le titre\n",
    "- texte sans stopwords, ponctuation, balises\n",
    "- stemming avec Krovetz\n",
    "\n",
    "<img src=\"images/learning_to_rank.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographie\n",
    "\n",
    "\n",
    "[1] <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.118.161&rep=rep1&type=pdf\">What Works Better for Question Answering: Stemming or\n",
    "Morphological Query Expansion?</a>\n",
    "\n",
    "[2] <a href=\"https://dl.acm.org/citation.cfm?id=160718\" >Viewing morphology as an inference process</a>\n",
    "\n",
    "[3] <a href=\"https://arxiv.org/pdf/1809.01682.pdf\">Deep Relevance Ranking Using Enhanced Document-Query Interactions</a>\n",
    "\n",
    "[4] <a href=\"http://delivery.acm.org/10.1145/2810000/2806475/p1411-kenter.pdf?ip=132.227.125.83&id=2806475&acc=ACTIVE%20SERVICE&key=7EBF6E77E86B478F%2EA72B4D473219EA0C%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1562588994_ca050bde6ad37b2c0d433db2e5df63ba\">Short Text Similarity with Word Embeddings</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
