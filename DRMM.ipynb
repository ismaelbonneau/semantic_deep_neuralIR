{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRMM (Deep Relevance Matching Model)\n",
    "\n",
    "\n",
    "But de ce notebook: Construire une architecture DRMM fonctionnelle avec Pytorch.\n",
    "\n",
    "Pour cela, 2 étapes:\n",
    "\n",
    "- construire la chaîne de pré traitements:\n",
    "    - générer des paires document-requête non pertinentes et pertinentes pour l'apprentissage\n",
    "    - générer des histogrammes d'interaction locales au niveau document-requête\n",
    "- construire l'architecture DRMM\n",
    "\n",
    "Les interractions sont pour le moment des interactions locales sur des word embeddings et sont mesurées comme une similarité cosinus entre les vecteurs des mots de la requête et ceux du document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import sep\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "embeddings_path = \"embeddings_wiki2017\"\n",
    "dataset_path = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré traitements: \n",
    "\n",
    "### Récupérer des word embeddings \n",
    "\n",
    "Ce word embedding a les caractéristiques suivantes:\n",
    "\n",
    "- Gensim Continuous Skipgram\n",
    "- taille de vecteur ${300}$\n",
    "- window ${5}$\n",
    "- entrainé sur wikipédia février 2017 en langue anglaise\n",
    "- pas de lemmatisation\n",
    "- ${302866}$ mots\n",
    "\n",
    "http://vectors.nlpl.eu/repository/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(embeddings_path + sep + \"model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = [w for w in model.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', vocabulary=vocabulary, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Récupère les paires de pertinence/non pertinence pour chaque requête \n",
    "\n",
    "On génère un dictionnaire qui contient pour chaque requête en clé, un dictionnaire contenant 2 listes:\n",
    "- \"relevant\" contenant des id de document pertinents pour la requête.\n",
    "- \"irrelevant\" contenant des id de document non pertinents pour la requête."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paires = {}\n",
    "\n",
    "with open(dataset_path + sep + \"qrels.robust2004.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        lol = line.split()\n",
    "        paires.setdefault(lol[0], {})\n",
    "        paires[lol[0]].setdefault('relevant', []) \n",
    "        paires[lol[0]].setdefault('irrelevant', [])\n",
    "        if lol[-1] == '1':\n",
    "            paires[lol[0]][\"relevant\"].append(lol[2])\n",
    "        else:\n",
    "            paires[lol[0]][\"irrelevant\"].append(lol[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On récupère les requêtes:\n",
    "\n",
    "Elles se trouvent sous forme de tuple ([mots clés], [texte de la requête]). On ne garde que les mots clés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "with open(dataset_path + sep + \"robust2004.txt\", \"r\") as f:\n",
    "    queries = ast.literal_eval(f.read())\n",
    "queries = {d:queries[d][0] for d in queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "international organized crime\n",
      "poliomyelitis and post polio\n"
     ]
    }
   ],
   "source": [
    "print(queries[\"301\"])\n",
    "print(queries[\"302\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_term_maxlen(queries):\n",
    "    return np.max([len(queries[q].split()) for q in queries])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut maintenant construire l'histogramme des interactions entre les embeddings de la requête et ceux du document.\n",
    "\n",
    "On prend comme exemple 4 bins: ${[-1, -0.5]}$ ${[-0.5, 0]}$ ${[0, 0.5]}$ ${[0.5, 1]}$.\n",
    "\n",
    "**Plusieurs manières de construire un histogramme**: compter le nombre de valeurs, compter puis normaliser..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "intvls = np.linspace(-1, 1, 5)\n",
    "\n",
    "def hist(query, document, intervals=intvls, normalize=False):\n",
    "    X = []\n",
    "    for i in query.nonzero()[1]:\n",
    "        histo = []\n",
    "        for j in document.nonzero()[1]:\n",
    "            histo.append(cosine_similarity([model.vectors[i]], [model.vectors[j]])[0][0])\n",
    "        histo, bin_edges = np.histogram(histo, bins=intervals)\n",
    "        if normalize:\n",
    "            histo = histo / histo.sum()\n",
    "        X.append(histo)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.transform([queries[\"301\"]])\n",
    "y = vectorizer.transform([\"I am a criminal and i kill\"]) #rajouter prétraitements\n",
    "y2 = vectorizer.transform([\"I am a peaceful dude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3 0]\n",
      " [0 0 3 0]\n",
      " [0 0 2 1]]\n"
     ]
    }
   ],
   "source": [
    "print(hist(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 2 0]\n",
      " [0 0 2 0]\n",
      " [0 0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "print(hist(x,y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture du modèle\n",
    "\n",
    "d'après <a href=\"https://dl.acm.org/citation.cfm?id=2983769\">les chinois</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Activation, Dot\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l'input pour les interactions\n",
    "interaction_input = Input(shape=(query_term_maxlen, hist_size), dtype='int32', name='interaction_input')\n",
    "\n",
    "#on construit le réseau feed forward\n",
    "z = Dense(layer_size[0], activation='tanh')(interaction_input)\n",
    "for dim in layer_size[1:]:\n",
    "    z = Dense(dim, activation='tanh')(z)\n",
    "\n",
    "#l'input pour le term gating network\n",
    "input_gating = Input(shape=(query_term_maxlen, embedding_size), name='term_gating_input')\n",
    "#le vecteur de poids du term gating network\n",
    "gating = Dense(query_term_maxlen, activation='softmax')(input_gating)\n",
    "\n",
    "#on fait la combinaison du feed forward et de la sortie du term gating\n",
    "s = Dot(x, gating)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
